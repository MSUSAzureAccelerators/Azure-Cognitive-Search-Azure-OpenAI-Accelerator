{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01a8b5c0-87cb-4302-8e3c-dc809d0039fb",
   "metadata": {},
   "source": [
    "# Understanding Memory in LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f73380-6395-4e9f-9c83-3f47a5d7e292",
   "metadata": {},
   "source": [
    "In the previous Notebook, we successfully explored how OpenAI models can enhance the results from Azure Cognitive Search. \n",
    "\n",
    "However, we have yet to discover how to engage in a conversation with the LLM. With [Bing Chat](http://chat.bing.com/), for example, this is possible, as it can understand and reference the previous responses.\n",
    "\n",
    "There is a common misconception that GPT models have memory. This is not true. While they possess knowledge, they do not retain information from previous questions asked to them.\n",
    "\n",
    "In this Notebook, our goal is to illustrate how we can effectively \"endow the LLM with memory\" by employing prompts and context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "733c782e-204c-47d0-8dae-c9df7091ab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.memory import CosmosDBChatMessageHistory\n",
    "\n",
    "from IPython.display import Markdown, HTML, display  \n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "#custom libraries that we will use later in the app\n",
    "from common.utils import (\n",
    "    get_search_results,\n",
    "    update_vector_indexes,\n",
    "    model_tokens_limit,\n",
    "    num_tokens_from_docs,\n",
    "    num_tokens_from_string,\n",
    "    get_answer,\n",
    ")\n",
    "\n",
    "from common.prompts import COMBINE_CHAT_PROMPT_TEMPLATE\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"credentials.env\")\n",
    "\n",
    "import logging\n",
    "\n",
    "# Get the root logger\n",
    "logger = logging.getLogger()\n",
    "# Set the logging level to a higher level to ignore INFO messages\n",
    "logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bc63c55-a57d-49a7-b6c7-0f18bca8199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc72b22-11c2-4df0-91b8-033d01829663",
   "metadata": {},
   "source": [
    "### Let's start with the basics\n",
    "Let's use a very simple example to see if the GPT model of Azure OpenAI have memory. We again will be using langchain to simplify our code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eef5dc9-8b80-4085-980c-865fa41fa1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"Tell me some use cases for reinforcement learning\"\n",
    "FOLLOW_UP_QUESTION = \"Give me the main points of our conversation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a00181d5-bd76-4ce4-a256-75ac5b58c60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "MODEL = \"gpt-35-turbo\"\n",
    "COMPLETION_TOKENS = 500\n",
    "# Create an OpenAI instance\n",
    "llm = AzureChatOpenAI(deployment_name=MODEL, temperature=0.5, max_tokens=COMPLETION_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9502d0f1-fddf-40d1-95d2-a1461dcc498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a very simple prompt template, just the question as is:\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"{question}\",\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5c9903e-15c7-4e05-87a1-58e5a7917ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Reinforcement learning can be applied to various domains and has several use cases. Here are some examples:\n",
       "\n",
       "1. Game playing: Reinforcement learning has been successfully used to train agents to play complex games like chess, Go, and video games. For example, AlphaGo, developed by DeepMind, used reinforcement learning to defeat world champion Go players.\n",
       "\n",
       "2. Robotics: Reinforcement learning can be applied to teach robots how to perform tasks, such as grasping objects, walking, or navigating through complex environments. It enables robots to learn from trial and error, improving their performance over time.\n",
       "\n",
       "3. Autonomous driving: Reinforcement learning can be used to train self-driving cars to make decisions in real-time, such as lane changing, merging, or navigating through traffic. It helps the vehicles adapt to changing road conditions and optimize their driving behavior.\n",
       "\n",
       "4. Recommendation systems: Reinforcement learning can be utilized to personalize recommendations for users in various domains like e-commerce, streaming platforms, or social media. It can learn user preferences and optimize recommendations based on user feedback.\n",
       "\n",
       "5. Finance and trading: Reinforcement learning can be employed to develop trading strategies and optimize portfolio management. Agents learn to make decisions on buying, selling, or holding assets based on market conditions and historical data.\n",
       "\n",
       "6. Healthcare: Reinforcement learning can assist in optimizing treatment plans and resource allocation in healthcare settings. It can learn to make decisions on patient scheduling, drug dosage, or disease management by considering patient outcomes and feedback.\n",
       "\n",
       "7. Energy management: Reinforcement learning can be used to optimize energy consumption and demand response in smart grids. It can learn to adjust energy usage based on real-time pricing, demand patterns, and environmental factors.\n",
       "\n",
       "8. Inventory management: Reinforcement learning can help businesses optimize their inventory levels and supply chain operations. It can learn to make decisions on when and how much to order, considering factors like demand patterns, lead times, and costs.\n",
       "\n",
       "9. Personalized education: Reinforcement learning can be applied to personalize educational content and adapt learning paths to individual students. It can learn to provide customized recommendations, exercises, or feedback based on student performance and engagement.\n",
       "\n",
       "10. Resource allocation: Reinforcement learning can be used to optimize resource allocation in various domains, such as scheduling tasks in project management, routing vehicles in logistics, or allocating server resources in cloud computing.\n",
       "\n",
       "These are just a few examples, and reinforcement learning can be applied to numerous other domains and problems where decision-making and optimization are involved."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's see what the GPT model responds\n",
    "response = chain.run(QUESTION)\n",
    "printmd(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99acaf3c-ce68-4b87-b24a-6065b15ff9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I apologize, but as an AI language model, I do not have the capability to recall past conversations. Once the conversation ends, the information is not stored or accessible to me. Is there anything else I can assist you with?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now let's ask a follow up question\n",
    "chain.run(FOLLOW_UP_QUESTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e1c143-c95f-4566-a8b4-af8c42f08dd2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "As you can see, it doesn't remember what it just responded, sometimes it responds based only on the system prompt, or just randomly. This proof that the LLM does NOT have memory and that we need to give the memory as a a conversation history as part of the prompt, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0946ce71-6285-432e-b011-9c2dc1ba7b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"question\"],\n",
    "    template=\"\"\"\n",
    "                {history}\n",
    "                Human: {question}\n",
    "                AI:\n",
    "            \"\"\"\n",
    "    )\n",
    "chain = LLMChain(llm=llm, prompt=hist_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d088e51-e5eb-4143-b87d-b2be429eb864",
   "metadata": {},
   "outputs": [],
   "source": [
    "Conversation_history = \"\"\"\n",
    "Human: {question}\n",
    "AI: {response}\n",
    "\"\"\".format(question=QUESTION, response=response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d99e34ad-5539-44dd-b080-3ad05efd2f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- Reinforcement learning can be applied to various domains and has several use cases.\n",
       "- Some examples include game playing, robotics, autonomous driving, recommendation systems, finance and trading, healthcare, energy management, inventory management, personalized education, and resource allocation.\n",
       "- Reinforcement learning allows agents to learn from trial and error and improve their performance over time.\n",
       "- It can optimize decision-making, adapt to changing conditions, and personalize experiences based on user feedback.\n",
       "- It can be used to optimize tasks such as grasping objects, navigating through traffic, managing portfolios, scheduling patients, adjusting energy usage, and allocating resources.\n",
       "- Reinforcement learning is a powerful tool for decision-making and optimization in a wide range of industries and applications."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd(chain.run({\"history\":Conversation_history, \"question\": FOLLOW_UP_QUESTION}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045e5af6-55d6-4353-b3f6-3275c95db00a",
   "metadata": {},
   "source": [
    "**Bingo!**, so we now know how to create a chatbot using LLMs, we just need to keep the state/history of the conversation and pass it as context every time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafd1694-0077-4aa8-bd01-e9f763ce36a3",
   "metadata": {},
   "source": [
    "## Now that we understand the concept of memory via adding history as a context, let's go back to our GPT Smart Search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba257e86-fd90-4a51-a72d-27000913e8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since Memory adds tokens to the prompt, we would need a better model that allows more space on the prompt\n",
    "MODEL = \"gpt-35-turbo-16k\"\n",
    "COMPLETION_TOKENS = 2000\n",
    "llm = AzureChatOpenAI(deployment_name=MODEL, temperature=0.5, max_tokens=COMPLETION_TOKENS)\n",
    "embedder = AzureOpenAIEmbeddings(deployment=\"text-embedding-ada-002\", chunk_size=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef9f459b-e8b8-40b9-a94d-80c079968594",
   "metadata": {},
   "outputs": [],
   "source": [
    "index1_name = \"cogsrch-index-files\"\n",
    "index2_name = \"cogsrch-index-csv\"\n",
    "index3_name = \"cogsrch-index-books-vector\"\n",
    "text_indexes = [index1_name, index2_name]\n",
    "vector_indexes = [index+\"-vector\" for index in text_indexes] + [index3_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b01852c2-6192-496c-adff-4270f9380469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of results: 5\n",
      "CPU times: user 1.11 s, sys: 52 ms, total: 1.16 s\n",
      "Wall time: 4.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Search in text-based indexes first and update vector indexes\n",
    "k=10 # Top k results per each text-based index\n",
    "ordered_results = get_search_results(QUESTION, text_indexes, k=k, reranker_threshold=1, vector_search=False)\n",
    "update_vector_indexes(ordered_search_results=ordered_results, embedder=embedder)\n",
    "\n",
    "# Search in all vector-based indexes available\n",
    "similarity_k = 5 # top results from multi-vector-index similarity search\n",
    "ordered_results = get_search_results(QUESTION, vector_indexes, k=k, vector_search=True,\n",
    "                                        similarity_k=similarity_k,\n",
    "                                        query_vector = embedder.embed_query(QUESTION))\n",
    "print(\"Number of results:\",len(ordered_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca500dd8-148c-4d8a-b58b-2df4c957459d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the below line if you want to inspect the ordered results\n",
    "# ordered_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b2a3595-c3b7-4376-b9c5-0db7a42b3ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 5\n"
     ]
    }
   ],
   "source": [
    "top_docs = []\n",
    "for key,value in ordered_results.items():\n",
    "    location = value[\"location\"] if value[\"location\"] is not None else \"\"\n",
    "    top_docs.append(Document(page_content=value[\"chunk\"], metadata={\"source\": location+os.environ['BLOB_SAS_TOKEN']}))\n",
    "        \n",
    "print(\"Number of chunks:\",len(top_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c26d7540-feb8-4581-849e-003f4bf2a601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System prompt token count: 2464\n",
      "Max Completion Token count: 2000\n",
      "Combined docs (context) token count: 2873\n",
      "--------\n",
      "Requested token count: 7337\n",
      "Token limit for gpt-35-turbo-16k : 16384\n",
      "Chain Type selected: stuff\n"
     ]
    }
   ],
   "source": [
    "# Calculate number of tokens of our docs\n",
    "if(len(top_docs)>0):\n",
    "    tokens_limit = model_tokens_limit(MODEL) # this is a custom function we created in common/utils.py\n",
    "    prompt_tokens = num_tokens_from_string(COMBINE_CHAT_PROMPT_TEMPLATE) # this is a custom function we created in common/utils.py\n",
    "    context_tokens = num_tokens_from_docs(top_docs) # this is a custom function we created in common/utils.py\n",
    "    \n",
    "    requested_tokens = prompt_tokens + context_tokens + COMPLETION_TOKENS\n",
    "    \n",
    "    chain_type = \"map_reduce\" if requested_tokens > 0.9 * tokens_limit else \"stuff\"  \n",
    "    \n",
    "    print(\"System prompt token count:\",prompt_tokens)\n",
    "    print(\"Max Completion Token count:\", COMPLETION_TOKENS)\n",
    "    print(\"Combined docs (context) token count:\",context_tokens)\n",
    "    print(\"--------\")\n",
    "    print(\"Requested token count:\",requested_tokens)\n",
    "    print(\"Token limit for\", MODEL, \":\", tokens_limit)\n",
    "    print(\"Chain Type selected:\", chain_type)\n",
    "        \n",
    "else:\n",
    "    print(\"NO RESULTS FROM AZURE SEARCH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ce6efa9-2b8f-4810-904d-5986b4ae0372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Some use cases for reinforcement learning include:\n",
       "1. Predictive strategies in multi-agent domains, where learning can give rise to social behaviors and individual robots can be programmed to produce certain group behaviors [22].\n",
       "2. Model-based learning, where agents build models of other agents via observations, such as learning a finite-state machine model of another agent [4].\n",
       "3. Learning agents in multi-agent systems, where agents use Q-learning or modified classifier systems to learn and converge to system-wide optimal behavior [28].\n",
       "4. Reinforcement learning simulations, which can be used to study the behavior of reinforcement learning agents and understand the relative importance of different parameters in an agent's learning algorithm [34].\n",
       "\n",
       "References:\n",
       "[4]<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v3.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\" target=\"_blank\">[4]</a></sup>\n",
       "[22]<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v3.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\" target=\"_blank\">[22]</a></sup>\n",
       "[28]<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v3.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\" target=\"_blank\">[28]</a></sup>\n",
       "[34]<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v3.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\" target=\"_blank\">[34]</a></sup>.\n",
       "\n",
       "Anything else I can help you with?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.2 ms, sys: 756 µs, total: 30 ms\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Get the answer\n",
    "response = get_answer(llm=llm, docs=top_docs, query=QUESTION, language=\"English\", chain_type=chain_type)\n",
    "printmd(response['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27501f1b-7db0-4ee3-9cb1-e609254ffa3d",
   "metadata": {},
   "source": [
    "And if we ask the follow up question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cf5b323-3b9c-479b-8502-acfc4f7915dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I'm sorry, but I couldn't find any extracted parts that provide the main points of our conversation."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = get_answer(llm=llm, docs=top_docs,  query=FOLLOW_UP_QUESTION, language=\"English\", chain_type=chain_type)\n",
    "printmd(response['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035fa6e6-226c-400f-a504-30255385f43b",
   "metadata": {},
   "source": [
    "You might get a different response from above, but it doesn't matter what response you get, it will be based on the context given, not on previous answers.\n",
    "\n",
    "Until now we just have the same as the prior Notebook 03: results from Azure Search enhanced by OpenAI model, with no memory\n",
    "\n",
    "**Now let's add memory to it:**\n",
    "\n",
    "Reference: https://python.langchain.com/docs/modules/memory/how_to/adding_memory_chain_multiple_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d98b876e-d264-48ae-b5ed-9801d6a9152b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Reinforcement learning has several use cases in various domains. Here are some examples:\n",
       "\n",
       "1. **Multi-robot domains**: Reinforcement learning has been studied in multi-robot domains, where learning can give rise to social behaviors and enable robots to individually program certain group behaviors<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup>.\n",
       "\n",
       "2. **Model-based learning**: In model-based learning, agents build models of other agents via observations. This approach has been used to effectively learn models based on finite state machines by observing the actions of other agents<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup>.\n",
       "\n",
       "3. **Agent coordination**: Reinforcement learning has been used to develop agent coordination in multi-agent systems (MASs). Learning agents in MASs can converge to system-wide optimal behavior, and different learning algorithms have been compared for agent coordination<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup>.\n",
       "\n",
       "4. **Market-based MASs**: Reinforcement learning has been studied in market-based MASs, where certain initial learning biases can be self-fulfilling. Learning agents in these systems can be affected by their models of other agents<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup>.\n",
       "\n",
       "5. **Healthcare research**: GIS (Geographic Information Systems) have been used as evidence-based practice tools in community health and healthcare research. They can inform and educate professionals and the public, empower decision-making, help in planning and predicting outcomes, change practices, and monitor changes in healthcare<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC343292/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[3]</a></sup>.\n",
       "\n",
       "6. **DNA synthesis**: Reinforcement learning has been used to reduce errors in synthetic DNA synthesis. A method called consensus shuffling has been developed, which involves re-hybridization of the population to reveal errors and remove them. This method improves the accuracy of synthetic DNA sequences<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1072806/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[2]</a></sup>.\n",
       "\n",
       "These are just a few examples of the use cases for reinforcement learning. The applications of reinforcement learning are diverse and continue to expand in various fields. \n",
       "\n",
       "References:\n",
       "1. [Reinforcement Learning in Multi-Robot Domains](https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D)\n",
       "2. [Consensus Shuffling Reduces Errors in Synthetic DNA](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1072806/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D)\n",
       "3. [The Potential of GIS in Community Health and Healthcare Research](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC343292/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D)\n",
       "\n",
       "Is there anything else I can help you with?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# memory object, which is neccessary to track the inputs/outputs and hold a conversation.\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\",input_key=\"question\")\n",
    "\n",
    "response = get_answer(llm=llm, docs=top_docs, query=QUESTION, language=\"English\", chain_type=chain_type, \n",
    "                        memory=memory)\n",
    "printmd(response['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf28927b-d9ee-4412-bb07-13e055e832a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on our conversation, here are the main points:\n",
       "\n",
       "1. Reinforcement learning has several use cases in various domains, including multi-robot domains, model-based learning, agent coordination in multi-agent systems, market-based multi-agent systems, healthcare research, and DNA synthesis<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup><sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1072806/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[2]</a></sup><sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC343292/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[3]</a></sup>.\n",
       "\n",
       "2. In multi-robot domains, reinforcement learning can give rise to social behaviors and enable robots to individually program certain group behaviors<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup>.\n",
       "\n",
       "3. Model-based learning involves agents building models of other agents via observations. This approach has been used to effectively learn models based on finite state machines by observing the actions of other agents<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup>.\n",
       "\n",
       "4. Reinforcement learning has been used to develop agent coordination in multi-agent systems (MASs), where learning agents can converge to system-wide optimal behavior<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup>.\n",
       "\n",
       "5. Reinforcement learning has been studied in market-based MASs, where certain initial learning biases can be self-fulfilling. The agents' models of other agents can affect their learning<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup>.\n",
       "\n",
       "6. GIS (Geographic Information Systems) have been used as evidence-based practice tools in community health and healthcare research. They can inform and educate professionals and the public, empower decision-making, help in planning and predicting outcomes, change practices, and monitor changes in healthcare<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC343292/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[3]</a></sup>.\n",
       "\n",
       "7. Reinforcement learning has been used to reduce errors in synthetic DNA synthesis. One method called consensus shuffling involves re-hybridization of the population to reveal errors and remove them, improving the accuracy of synthetic DNA sequences<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1072806/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[2]</a></sup>.\n",
       "\n",
       "These are the main points from our conversation. Let me know if there's anything else I can assist you with."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now we add a follow up question:\n",
    "response = get_answer(llm=llm, docs=top_docs, query=FOLLOW_UP_QUESTION, language=\"English\", chain_type=chain_type, \n",
    "                      memory=memory)\n",
    "printmd(response['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3830b0b8-0ca2-4d0a-9747-f6273368002b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I'm sorry, but I couldn't find any relevant information in the extracted parts that directly answers your question about the main points of our conversation. Is there anything else I can assist you with?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Another follow up query\n",
    "response = get_answer(llm=llm, docs=top_docs, query=\"Thank you\", language=\"English\", chain_type=chain_type,  \n",
    "                      memory=memory)\n",
    "printmd(response['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111e732b-3c8c-4df3-8fcb-c3d01e7bec74",
   "metadata": {},
   "source": [
    "You might get a different answer on the above cell, and it is ok, this bot is not yet well configured to answer any question that is not related to its knowledge base, including salutations.\n",
    "\n",
    "Let's check our memory to see that it's keeping the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1279692c-7eb0-4300-8a66-c7025f02c318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: Tell me some use cases for reinforcement learning\\nAI: Reinforcement learning has several use cases in various domains. Here are some examples:\\n\\n1. **Multi-robot domains**: Reinforcement learning has been studied in multi-robot domains, where learning can give rise to social behaviors and enable robots to individually program certain group behaviors<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup>.\\n\\n2. **Model-based learning**: In model-based learning, agents build models of other agents via observations. This approach has been used to effectively learn models based on finite state machines by observing the actions of other agents<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup>.\\n\\n3. **Agent coordination**: Reinforcement learning has been used to develop agent coordination in multi-agent systems (MASs). Learning agents in MASs can converge to system-wide optimal behavior, and different learning algorithms have been compared for agent coordination<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup>.\\n\\n4. **Market-based MASs**: Reinforcement learning has been studied in market-based MASs, where certain initial learning biases can be self-fulfilling. Learning agents in these systems can be affected by their models of other agents<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup>.\\n\\n5. **Healthcare research**: GIS (Geographic Information Systems) have been used as evidence-based practice tools in community health and healthcare research. They can inform and educate professionals and the public, empower decision-making, help in planning and predicting outcomes, change practices, and monitor changes in healthcare<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC343292/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[3]</a></sup>.\\n\\n6. **DNA synthesis**: Reinforcement learning has been used to reduce errors in synthetic DNA synthesis. A method called consensus shuffling has been developed, which involves re-hybridization of the population to reveal errors and remove them. This method improves the accuracy of synthetic DNA sequences<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1072806/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[2]</a></sup>.\\n\\nThese are just a few examples of the use cases for reinforcement learning. The applications of reinforcement learning are diverse and continue to expand in various fields. \\n\\nReferences:\\n1. [Reinforcement Learning in Multi-Robot Domains](https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D)\\n2. [Consensus Shuffling Reduces Errors in Synthetic DNA](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1072806/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D)\\n3. [The Potential of GIS in Community Health and Healthcare Research](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC343292/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D)\\n\\nIs there anything else I can help you with?\\nHuman: Give me the main points of our conversation\\nAI: Based on our conversation, here are the main points:\\n\\n1. Reinforcement learning has several use cases in various domains, including multi-robot domains, model-based learning, agent coordination in multi-agent systems, market-based multi-agent systems, healthcare research, and DNA synthesis<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup><sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1072806/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[2]</a></sup><sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC343292/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[3]</a></sup>.\\n\\n2. In multi-robot domains, reinforcement learning can give rise to social behaviors and enable robots to individually program certain group behaviors<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup>.\\n\\n3. Model-based learning involves agents building models of other agents via observations. This approach has been used to effectively learn models based on finite state machines by observing the actions of other agents<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup>.\\n\\n4. Reinforcement learning has been used to develop agent coordination in multi-agent systems (MASs), where learning agents can converge to system-wide optimal behavior<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup>.\\n\\n5. Reinforcement learning has been studied in market-based MASs, where certain initial learning biases can be self-fulfilling. The agents\\' models of other agents can affect their learning<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup>.\\n\\n6. GIS (Geographic Information Systems) have been used as evidence-based practice tools in community health and healthcare research. They can inform and educate professionals and the public, empower decision-making, help in planning and predicting outcomes, change practices, and monitor changes in healthcare<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC343292/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[3]</a></sup>.\\n\\n7. Reinforcement learning has been used to reduce errors in synthetic DNA synthesis. One method called consensus shuffling involves re-hybridization of the population to reveal errors and remove them, improving the accuracy of synthetic DNA sequences<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1072806/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[2]</a></sup>.\\n\\nThese are the main points from our conversation. Let me know if there\\'s anything else I can assist you with.\\nHuman: Thank you\\nAI: I\\'m sorry, but I couldn\\'t find any relevant information in the extracted parts that directly answers your question about the main points of our conversation. Is there anything else I can assist you with?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87405173",
   "metadata": {},
   "source": [
    "## Using CosmosDB as persistent memory\n",
    "\n",
    "In previous cell we have added local RAM memory to our chatbot. However, it is not persistent, it gets deleted once the app user's session is terminated. It is necessary then to use a Database for persistent storage of each of the bot user conversations, not only for Analytics and Auditing, but also if we wisg to provide recommendations. \n",
    "\n",
    "Here we will store the conversation history into CosmosDB for future auditing purpose.\n",
    "We will use a class in LangChain use CosmosDBChatMessageHistory, see [HERE](https://python.langchain.com/en/latest/_modules/langchain/memory/chat_message_histories/cosmos_db.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7131daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CosmosDB instance from langchain cosmos class.\n",
    "cosmos = CosmosDBChatMessageHistory(\n",
    "    cosmos_endpoint=os.environ['AZURE_COSMOSDB_ENDPOINT'],\n",
    "    cosmos_database=os.environ['AZURE_COSMOSDB_NAME'],\n",
    "    cosmos_container=os.environ['AZURE_COSMOSDB_CONTAINER_NAME'],\n",
    "    connection_string=os.environ['AZURE_COMOSDB_CONNECTION_STRING'],\n",
    "    session_id=\"Agent-Test-Session\" + str(random.randint(1, 1000)),\n",
    "    user_id=\"Agent-Test-User\" + str(random.randint(1, 1000))\n",
    "    )\n",
    "\n",
    "# prepare the cosmosdb instance\n",
    "cosmos.prepare_cosmos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d87cc7c6-5ef1-4492-b133-9f63a392e223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or Memory Object\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\",input_key=\"question\",chat_memory=cosmos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27ceb47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Reinforcement learning has several use cases in various domains. Here are some examples:\n",
       "\n",
       "1. Multi-robot domains: Reinforcement learning can be used to study the behavior of multiple robots in a coordinated manner. For example, researchers have shown how learning can give rise to social behaviors in robot groups, where individual robots are programmed to produce certain group behaviors<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup>.\n",
       "\n",
       "2. Model-based learning: In model-based learning, agents build models of other agents through observations. This approach can be used to effectively learn models of other agents' behaviors. For example, agents can learn finite-state machine models of other agents through observation of their actions<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup>.\n",
       "\n",
       "3. Agent coordination: Reinforcement learning agents can be used to develop coordination among multiple agents in a multi-agent system. Learning algorithms, such as Q-learning or modified classifier systems, can be used to help agents converge to system-wide optimal behavior<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup>.\n",
       "\n",
       "4. Synthetic DNA synthesis: Reinforcement learning can be used to improve the synthesis of synthetic DNA by reducing random errors. For example, a method called consensus shuffling has been developed to remove mismatches in synthetic DNA fragments, resulting in improved synthesis accuracy<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1072806/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[2]</a></sup>.\n",
       "\n",
       "5. Geographic Information Systems (GIS): GIS can be used as evidence-based practice tools for community health improvement. GIS can inform and educate professionals and the public, empower decision-making, help in planning and prioritization, and monitor and analyze changes in community health<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC343292/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[3]</a></sup>.\n",
       "\n",
       "6. Protein sequence analysis: Reinforcement learning can be used to find new protein hits in repeated PSI-BLAST searches. A tool called ReHAB compares results from PSI-BLAST searches performed with different versions of a protein sequence database and highlights new hits that are present only in the updated database<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC549547/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[4]</a></sup>.\n",
       "\n",
       "These are just a few examples of the use cases for reinforcement learning. The field is continually evolving, and new applications are being discovered."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing using our Question\n",
    "response = get_answer(llm=llm, docs=top_docs, query=QUESTION, language=\"English\", chain_type=chain_type, \n",
    "                        memory=memory)\n",
    "printmd(response['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a5ff826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on our conversation, here are the main points:\n",
       "\n",
       "1. Reinforcement learning has several use cases in various domains.\n",
       "2. In multi-robot domains, reinforcement learning can be used to study the behavior of multiple robots in a coordinated manner<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup>.\n",
       "3. Model-based learning allows agents to build models of other agents through observations<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup>.\n",
       "4. Reinforcement learning agents can be used to develop coordination among multiple agents in a multi-agent system<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup>.\n",
       "5. Reinforcement learning can be used to improve the synthesis of synthetic DNA by reducing random errors<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1072806/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[2]</a></sup>.\n",
       "6. Geographic Information Systems (GIS) can be used as evidence-based practice tools for community health improvement<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC343292/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[3]</a></sup>.\n",
       "7. Reinforcement learning can be used for protein sequence analysis to find new hits in repeated PSI-BLAST searches<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC549547/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[4]</a></sup>.\n",
       "\n",
       "These points highlight the diverse applications of reinforcement learning in fields such as robotics, DNA synthesis, community health, and protein analysis."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now we add a follow up question:\n",
    "response = get_answer(llm=llm, docs=top_docs, query=FOLLOW_UP_QUESTION, language=\"English\", chain_type=chain_type, \n",
    "                      memory=memory)\n",
    "printmd(response['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be1620fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the extracted parts from the documents, here are the main points of our conversation:\n",
       "\n",
       "1. Reinforcement learning has several use cases in various domains, including multi-robot domains, model-based learning, agent coordination, synthetic DNA synthesis, Geographic Information Systems (GIS), and protein sequence analysis<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup><sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1072806/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[2]</a></sup><sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC343292/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[3]</a></sup><sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC549547/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[4]</a></sup>.\n",
       "\n",
       "2. Reinforcement learning can be used to study the behavior of multiple robots in a coordinated manner, leading to the emergence of social behaviors in robot groups<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup>.\n",
       "\n",
       "3. Model-based learning allows agents to build models of other agents through observations, which can be effectively learned via observation of the other agent's actions<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup>.\n",
       "\n",
       "4. Reinforcement learning agents can be used to develop coordination among multiple agents in a multi-agent system, leading to system-wide optimal behavior<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup>.\n",
       "\n",
       "5. Reinforcement learning can be used to improve the synthesis of synthetic DNA by reducing random errors, such as through the consensus shuffling method<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1072806/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[2]</a></sup>.\n",
       "\n",
       "6. Geographic Information Systems (GIS) can be used as evidence-based practice tools for community health improvement, informing decision-making, planning, and monitoring changes in community health<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC343292/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[3]</a></sup>.\n",
       "\n",
       "7. Reinforcement learning can be used in protein sequence analysis to find new hits in repeated PSI-BLAST searches, facilitating the synthesis of long DNA sequences<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC549547/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[4]</a></sup>.\n",
       "\n",
       "These points summarize the main topics we discussed regarding the use cases of reinforcement learning. If you have any more questions or need further information, feel free to ask!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Another follow up query\n",
    "response = get_answer(llm=llm, docs=top_docs, query=\"Thank you\", language=\"English\", chain_type=chain_type,  \n",
    "                      memory=memory)\n",
    "printmd(response['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc5ac98",
   "metadata": {},
   "source": [
    "Let's check our Azure CosmosDB to see the whole conversation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1d7688a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Tell me some use cases for reinforcement learning'),\n",
       " AIMessage(content='Reinforcement learning has several use cases in various domains. Here are some examples:\\n\\n1. Multi-robot domains: Reinforcement learning can be used to study the behavior of multiple robots in a coordinated manner. For example, researchers have shown how learning can give rise to social behaviors in robot groups, where individual robots are programmed to produce certain group behaviors<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup>.\\n\\n2. Model-based learning: In model-based learning, agents build models of other agents through observations. This approach can be used to effectively learn models of other agents\\' behaviors. For example, agents can learn finite-state machine models of other agents through observation of their actions<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup>.\\n\\n3. Agent coordination: Reinforcement learning agents can be used to develop coordination among multiple agents in a multi-agent system. Learning algorithms, such as Q-learning or modified classifier systems, can be used to help agents converge to system-wide optimal behavior<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup>.\\n\\n4. Synthetic DNA synthesis: Reinforcement learning can be used to improve the synthesis of synthetic DNA by reducing random errors. For example, a method called consensus shuffling has been developed to remove mismatches in synthetic DNA fragments, resulting in improved synthesis accuracy<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1072806/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[2]</a></sup>.\\n\\n5. Geographic Information Systems (GIS): GIS can be used as evidence-based practice tools for community health improvement. GIS can inform and educate professionals and the public, empower decision-making, help in planning and prioritization, and monitor and analyze changes in community health<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC343292/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[3]</a></sup>.\\n\\n6. Protein sequence analysis: Reinforcement learning can be used to find new protein hits in repeated PSI-BLAST searches. A tool called ReHAB compares results from PSI-BLAST searches performed with different versions of a protein sequence database and highlights new hits that are present only in the updated database<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC549547/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[4]</a></sup>.\\n\\nThese are just a few examples of the use cases for reinforcement learning. The field is continually evolving, and new applications are being discovered.'),\n",
       " HumanMessage(content='Give me the main points of our conversation'),\n",
       " AIMessage(content='Based on our conversation, here are the main points:\\n\\n1. Reinforcement learning has several use cases in various domains.\\n2. In multi-robot domains, reinforcement learning can be used to study the behavior of multiple robots in a coordinated manner<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup>.\\n3. Model-based learning allows agents to build models of other agents through observations<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup>.\\n4. Reinforcement learning agents can be used to develop coordination among multiple agents in a multi-agent system<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup>.\\n5. Reinforcement learning can be used to improve the synthesis of synthetic DNA by reducing random errors<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1072806/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[2]</a></sup>.\\n6. Geographic Information Systems (GIS) can be used as evidence-based practice tools for community health improvement<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC343292/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[3]</a></sup>.\\n7. Reinforcement learning can be used for protein sequence analysis to find new hits in repeated PSI-BLAST searches<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC549547/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[4]</a></sup>.\\n\\nThese points highlight the diverse applications of reinforcement learning in fields such as robotics, DNA synthesis, community health, and protein analysis.'),\n",
       " HumanMessage(content='Thank you'),\n",
       " AIMessage(content='Based on the extracted parts from the documents, here are the main points of our conversation:\\n\\n1. Reinforcement learning has several use cases in various domains, including multi-robot domains, model-based learning, agent coordination, synthetic DNA synthesis, Geographic Information Systems (GIS), and protein sequence analysis<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup><sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1072806/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[2]</a></sup><sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC343292/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[3]</a></sup><sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC549547/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[4]</a></sup>.\\n\\n2. Reinforcement learning can be used to study the behavior of multiple robots in a coordinated manner, leading to the emergence of social behaviors in robot groups<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup>.\\n\\n3. Model-based learning allows agents to build models of other agents through observations, which can be effectively learned via observation of the other agent\\'s actions<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup>.\\n\\n4. Reinforcement learning agents can be used to develop coordination among multiple agents in a multi-agent system, leading to system-wide optimal behavior<sup><a href=\"https://blobstoragey24bi577jszf6.blob.core.windows.net/arxivcs/0001/0001008v2.pdf?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[1]</a></sup>.\\n\\n5. Reinforcement learning can be used to improve the synthesis of synthetic DNA by reducing random errors, such as through the consensus shuffling method<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1072806/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[2]</a></sup>.\\n\\n6. Geographic Information Systems (GIS) can be used as evidence-based practice tools for community health improvement, informing decision-making, planning, and monitoring changes in community health<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC343292/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[3]</a></sup>.\\n\\n7. Reinforcement learning can be used in protein sequence analysis to find new hits in repeated PSI-BLAST searches, facilitating the synthesis of long DNA sequences<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC549547/?sv=2023-01-03&ss=btqf&srt=sco&st=2023-12-15T13%3A10%3A02Z&se=2030-12-16T11%3A00%3A00Z&sp=rl&sig=csDdBE4LlNa0VmLDMUbbY6pcly9wKr5f8XKFpKRfq64%3D\">[4]</a></sup>.\\n\\nThese points summarize the main topics we discussed regarding the use cases of reinforcement learning. If you have any more questions or need further information, feel free to ask!')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load message from cosmosdb\n",
    "cosmos.load_messages()\n",
    "cosmos.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e30694-ae2a-47bb-a5c7-db51ecdbba1e",
   "metadata": {},
   "source": [
    "![CosmosDB Memory](./images/cosmos-chathistory.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6789cada-23a3-451a-a91a-0906ceb0bd14",
   "metadata": {},
   "source": [
    "# Summary\n",
    "##### Adding memory to our application allows the user to have a conversation, however this feature is not something that comes with the LLM, but instead, memory is something that we must provide to the LLM in form of context of the question.\n",
    "\n",
    "We added persitent memory using CosmosDB.\n",
    "\n",
    "We also can notice that the current chain that we are using is smart, but not that much. Although we have given memory to it, it searches for similar docs everytime, regardless of the input and it struggles to respond to prompts like: Hello, Thank you, Bye, What's your name, What's the weather and any other task that is not search in the knowledge base.\n",
    "\n",
    "\n",
    "## <u>Important Note</u>:<br>\n",
    "As we proceed, while all the code will remain compatible with GPT-3.5 models, we highly recommend transitioning to GPT-4. Here's why:\n",
    "\n",
    "**GPT-3.5-Turbo** can be likened to a 7-year-old child. You can provide it with concise instructions, but it frequently struggles to follow them accurately. Additionally, its limited memory can make sustained conversations challenging.\n",
    "\n",
    "**GPT-3.5-Turbo-16k** resembles the same 7-year-old, but with an increased attention span for longer instructions. However, it still faces difficulties accurately executing them about half the time.\n",
    "\n",
    "**GPT-4** exhibits the capabilities of a 10-12-year-old child. It possesses enhanced reasoning skills and more consistently adheres to instructions. While its memory retention for instructions is moderate, it excels at following them.\n",
    "\n",
    "**GPT-4-32k** is akin to the 10-12-year-old child with an extended memory. It comprehends lengthy sets of instructions and engages in meaningful conversations. Thanks to its robust memory, it offers detailed responses.\n",
    "\n",
    "Understanding this analogy above will become clearer as you complete the final notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c629ebf4-aced-45b7-a6a2-315810d37d48",
   "metadata": {},
   "source": [
    "# NEXT\n",
    "We know now how to do a Smart Search Engine that can power a chatbot!! great!\n",
    "\n",
    "But, does this solve all the possible scenarios that a virtual assistant will require?  **What about if the answer to the Smart Search Engine is not related to text, but instead requires to look into tabular data?** The next notebook explains and solves the tabular problem and the concept of Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4d9da4-3918-4da6-b235-a3320f0dcb12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
